<html xmlns="http://www.w3.org/1999/xhtml">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>Removing Diffraction Image Artifacts in Under-Display Camera</title>
  <!--=================Meta tags==========================-->
  <meta name="robots" content="index,follow">
  <meta name="keywords" content="image restoration, UDC">
  <link rel="author" href="https://jnjaby.github.io/projects/UDC">
  <!--=================js==========================-->
  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>

  <link href="./css.css" rel="stylesheet" type="text/css">
  <link rel="stylesheet" type="text/css" href="../project.css" media="screen">
  <script src="./effect.js "></script>
  <!-- Latex -->
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
        TeX: { equationNumbers: { autoNumber: "AMS" } },
      });
      </script>
  <script type="text/javascript" async
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML">
    </script>
  <!--=================Google Analytics==========================-->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-129775907-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }
    gtag('js', new Date());

    gtag('config', 'UA-129775907-1');
  </script>
</head>

<body>
  <div id="content">
    <div id="content-inner">
      <div class="section head">
        <h1>
          Removing Diffraction Image Artifacts in Under-Display 
        </h1>
        <h1>
          Camera via Dynamic Skip Connection Networks
        </h1>
        <!--=================Authors==========================-->
        <div class="authors">
          <a href="https://jnjaby.github.io/" target="_blank">Ruicheng Feng</a> <sup>1</sup>
          &nbsp;&nbsp;&nbsp;&nbsp;
          <a href="https://li-chongyi.github.io/" target="_blank">Chongyi Li</a> <sup>1</sup>
          &nbsp;&nbsp;&nbsp;&nbsp;
          <a href="https://hc25.web.rice.edu/" target="_blank">Huaijin Chen</a> <sup>2</sup>
          &nbsp;&nbsp;&nbsp;&nbsp;
          <a href="https://scholar.google.com/citations?user=mFG5Sv4AAAAJ&hl=en/" target="_blank">Shuai Li</a> <sup>2</sup>
          &nbsp;&nbsp;&nbsp;&nbsp;
          <a href="https://personal.ie.cuhk.edu.hk/~ccloy/" target="_blank">
            Chen Change Loy</a> <sup>1</sup>
            &nbsp;&nbsp;&nbsp;&nbsp;
          <a href="https://www.gujinwei.org/" target="_blank">Jinwei Gu</a> <sup>2,3</sup>
        </div>

        <div class="affiliations ">
          <sup>1</sup> S-Lab, Nanyang Technological University<br>
          <sup>2</sup> Tetras.AI<br>
          <sup>3</sup> Shanghai AI Laboratory
        </div>
        <!--=================Tabs==========================-->
        <ul id="tabs">
          <li><a href="#abstract" name="#tab1">Abstract</a></li>
          <li><a href="#dataset" name="#tab2">Dataset</a></li>
          <li><a href="#method" name="#tab3">Method</a></li>
          <li><a href="#results" name="#tab4">Results</a></li>
          <li><a href="#citation" name="#tab5">Citation</a></li>
      </div>
      <br>
      <!--=================Teasers==========================-->
      <div class="container">
        <div>
          <table width="90%" align="center" cellspacing="0" cellpadding="30px">
            <tbody><tr>
          <td style="padding:0 10px 10px 10px;">
            <img src="src/syn_LQ1.png" onmouseover="this.src='src/syn_GT1.png';" onmouseout="this.src='src/syn_LQ1.png';" height="280" width="280">
          </td>
          <td style="padding:0 10px 10px 10px;">
            <img src="src/syn_LQ2.png" onmouseover="this.src='src/syn_GT2.png';" onmouseout="this.src='src/syn_LQ2.png';" height="280" width="280">
          </td>
          <td style="padding:0 10px 10px 10px;">	
            <img src="src/syn_LQ3.png" onmouseover="this.src='src/syn_GT3.png';" onmouseout="this.src='src/syn_LQ3.png';" height="280" width="280">
          </td></tr>
          <tr>
          <td style="padding:0 10px 10px 10px;">			  
            <img src="src/syn_LQ4.png" onmouseover="this.src='src/syn_GT4.png';" onmouseout="this.src='src/syn_LQ4.png';" height="280" width="280">
          </td>	  
          <td style="padding:0 10px 10px 10px;">			  
            <img src="src/syn_LQ5.png" onmouseover="this.src='src/syn_GT5.png';" onmouseout="this.src='src/syn_LQ5.png';" height="280" width="280">
          </td>
          <td style="padding:0 10px 10px 10px;">			  
            <img src="src/syn_LQ6.png" onmouseover="this.src='src/syn_GT6.png';" onmouseout="this.src='src/syn_LQ6.png';" height="280" width="280">
          </td>
          </tr></tbody></table>
        </div>
        <p align="center">
          <b>MouseOut</b>: Degraded images&emsp;&emsp;&emsp;&emsp;
          <b>MouseOver</b>: Restored results
        </p>
      </div>

      <!--=================Abstract==========================-->
      <div class="section abstract", id="abstract">
        <h2>Abstract</h2>
        <p>
          <br>
          Recent development of Under-Display Camera (UDC) systems provides a true bezel-less and notch-free viewing experience on smartphones (and TV, laptops, tablets), while allowing images to be captured from the selfie camera embedded underneath. In a typical UDC system, the microstructure of the semi-transparent organic light-emitting
          diode (OLED) pixel array attenuates and diffracts the incident
          light on the camera, resulting in significant image
          quality degradation. Often times, noise, flare, haze, and
          blur can be observed in UDC images. In this work, we aim
          to analyze and tackle the aforementioned degradation problems.
          We define a physics-based image formation model to
          better understand the degradation. In addition, we utilize
          one of the worldâ€™s first commodity UDC smartphone prototypes
          to measure the real-world Point Spread Function
          (PSF) of the UDC system, and provide a model-based data
          synthesis pipeline to generate realistically degraded images.
          We specially design a new domain knowledge-enabled
          Dynamic Skip Connection Network (DISCNet) to restore
          the UDC images. We demonstrate the effectiveness of our
          method through extensive experiments on both synthetic and
          real UDC data. Our physics-based image formation model and proposed DISCNet can provide foundations for further exploration in UDC image restoration, and even for general diffraction artifact removal in a broader sense.
        </p>
      </div>



      <!--=================Materials==========================-->
      <div class="section materials" , id="materials">
        <h2>Materials</h2>
        <br>
        <table width="100%" align="center" border=none cellspacing="0" cellpadding="30">
          <tr>
            <td width="30%">
              <center>
                <a href="https://arxiv.org/abs/2104.09556" target="_blank" class="imageLink"><img
                    src="./src/thumbnail.png" , height="120"></a><br>
                <a href="https://arxiv.org/abs/2104.09556" disabled target="_blank">Paper</a>
              </center>
            </td>
            <td width="30%">
              <center>
                <a href="https://github.com/jnjaby/DISCNet/tree/main/datasets" target="_blank" class="imageLink"><img
                    src="../icon_dataset.png" , height="120"></a><br>
                <a href="https://github.com/jnjaby/DISCNet/tree/main/datasets" target="_blank">Data</a>
              </center>
            </td>
            <td width="30%" valign="middle">
              <center>
                <a href="https://github.com/jnjaby/DISCNet" target="_blank" class="imageLink"><img
                    src="../icon_github.png" , height="120"></a><br>
                <a href="https://github.com/jnjaby/DISCNet" target="_blank">Codes</a>
              </center>
            </td>
          </tr>
        </table>
      </div>
    </div>


      <!--=================What is UDC==========================-->
      <div class="section" , id="UDC">
        <h2>What is UDC?</h2>
        <div style="text-align: center; vertical-align:middle">
          <img src="src/schematic.png" width="880">
        </div>
        <p>
          As the above figure shows,
          a typical UDC system has the camera module placed underneath
          and closely attached to the semi-transparent Organic
          Light-Emitting Diode (OLED) display. Although the
          display looks partially transparent, the regions where the
          light can pass through, i.e. the gaps between the display pixels,
          are usually in the micrometer scale, which substantially
          diffracts the incoming light, affecting the light propagation from the scene to the sensor.
          In particular, the light emitted from a point light
          source is modulated by the OLED and camera lens, before being
          captured by the sensor.
          The UDC systems introduce a new class of complex image degradation problems, combining <strong>flare</strong>, <strong>haze</strong>, <strong>blur</strong>, and <strong>noise</strong>. On the right there is a simulated example of the image formation model with a real-captured PSF.
        </p>
      </div>


      <!--=================Dataset==========================-->
      <div class="section" , id="dataset">
        <h2>Dataset</h2>
        <p>
          We provide both the synthetic and real dataset for Under-Display Camera Images. Train and validation subsets are publicly available. Downloads are available via Google Drive or running the python code.
        </p>
        <p>
          For synthetic data, we gather 2016 HDR patches of size [800, 800, 3] for training and 360 pairs for testing. Since these patches are reprojected and cropped from the 360-degree panorama, they may exhibit some overlap contents (but in different perspective view). Image values are ranging from [0, 500] and constructed in '.npy' form. For each of the crops, we release the ground-truth iamges and you can simulate the corresponding degraded image with calibrated PSFs by running the code. 
        </p>
        <p>
          For real data, we release 30 HDR images of size [3264, 2448, 3] using ZTE phone. Similarly, image values are ranging from [0, 16] and constructed in '.npy' form. Images are in linear domain and are not processed by the built-in ISP of the phone. We provide a simple pipeline of post-processing for better visulization. The camera output of the phone (after ISP) are also released for reference and color correction pipeline.
        </p>
      </div>


      <!--=================Method==========================-->
      <div class="section" , id="method">
        <h2>Method</h2>
        <div style="text-align: center; vertical-align:middle">
          <img src="src/architecture.png" width="730">
        </div>
        <div align="center">
          Overview of our proposed Dynamic Skip Connection Network (DISCNet).
        </div>
        <p>
           The main restoration branch consists of an encoder and a decoder, with feature maps propagated and transformed by DISCNet through skip connections. DISCNet applies multi-scale dynamic convolutions using generated filters conditioned on PSF kernel code and spatial information from input images.
        </p>
      </div>


      <!--=================Results==========================-->
      <div class="section" , id="results">
        <h2>Results</h2>
        <br>
        <table>
          <tr>
            <div style="text-align: center; vertical-align:middle">
              <img src="src/syn_visual_result.png" width="780">
            </div>
          </tr>
          <tr>
            <div style="text-align: center; vertical-align:middle">
              <img src="src/syn_plant.png" width="780">
            </div>
          </tr>
          <tr>
            <div style="text-align: center; vertical-align:middle">
              <img src="src/syn_shanghai2.png" width="780">
            </div>
          </tr>
          <tr>
            <div align="center">
              Visual results on synthetic data.
            </div>    
          </tr>
        </table>
        <br><br>
        <table>
          <tr>
            <div style="text-align: center; vertical-align:middle">
              <img src="src/real_vusual_result.png" width="780">
            </div>
          </tr>
          <tr>
            <div style="text-align: center; vertical-align:middle">
              <img src="src/real_cafe.png" width="780">
            </div>
          </tr>
          <tr>
            <div style="text-align: center; vertical-align:middle">
              <img src="src/real_canteen2.png" width="780">
            </div>
          </tr>
          <tr>
            <div align="center">
              Visual results on real data.
            </div>    
          </tr>
        </table>
      </div>

      <!--=================License==========================-->
      <div class="section" , id="License">
        <h2>License</h2>
        <p>
          The dataset is made available for academic research purpose only. All the images from synthetic dataset are collected from the Internet, and the copyright belongs to the original owners. If any of the images belongs to you and you would like it removed, kindly inform us, we will remove it from our dataset immediately. The real dataset is collected and uploaded by us. We retain all the copyrights of them.
        </p>
      </div>


      <!--=================Citation==========================-->
      <div class="section citation" , id="citation">
        <h2>Citation</h2>
        If you find our dataset and paper useful for your research, please consider citing our work:
        <div class="section bibtex">
          <pre>@inproceedings{feng2021removing,
          author = {Feng, Ruicheng and Li, Chongyi and Chen, Huaijin and Li, Shuai and Loy, Chen Change and Gu, Jinwei},
          title = {Removing Diffraction Image Artifacts in Under-Display Camera via Dynamic Skip Connection Networks},
          booktitle = {IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
          year = {2021}
          }
          </pre>
        </div>
      </div>

      <!--=================Contact==========================-->
      <div class="section contact">
        <h2 id="contact">Contact</h2>
        <p>If you have any question, please contact us via <strong>ruicheng002@ntu.edu.sg</strong>.
        </p>
        <br>
      </div>
</body>

</html>
